---
title: "Seventh Week: Generalized Linear Models"
subtitle: "Murder or suicide"
author: "student name"
date: "`r Sys.time()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

> <p dir="RTL"> 
با توجه به سوالات مرگ و میر در آمریکا به سوالات زیر پاسخ دهید.
</p>

***

<p dir="RTL">
۱. از میان متغیرهای داده مرگ و میر یک زیرمجموعه ایی بدون حشو در نظر بگیرید.
ماتریس همبستگی متغیرهای مختلف را به دست آورده و سپس رسم نمایید. علاوه بر این نمودار پراکنش متغیرهای انتخاب شده را همزمان نسبت به هم رسم نمایید.
</p>

<p dir = "RTL">
پاسخ :
</p>

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(reshape2)
library(car)

source('../week_7_14/unbalanced_functions.R')
cor2 = function(df){
  
  stopifnot(inherits(df, "data.frame"))
  stopifnot(sapply(df, class) %in% c("integer"
                                     , "numeric"
                                     , "factor"
                                     , "character"))
  
  cor_fun <- function(pos_1, pos_2){
    
    # both are numeric
    if(class(df[[pos_1]]) %in% c("integer", "numeric") &&
       class(df[[pos_2]]) %in% c("integer", "numeric")){
      r <- stats::cor(df[[pos_1]]
                      , df[[pos_2]]
                      , use = "pairwise.complete.obs"
      )
    }
    
    # one is numeric and other is a factor/character
    if(class(df[[pos_1]]) %in% c("integer", "numeric") &&
       class(df[[pos_2]]) %in% c("factor", "character")){
      r <- sqrt(
        summary(
          stats::lm(df[[pos_1]] ~ as.factor(df[[pos_2]])))[["r.squared"]])
    }
    
    if(class(df[[pos_2]]) %in% c("integer", "numeric") &&
       class(df[[pos_1]]) %in% c("factor", "character")){
      r <- sqrt(
        summary(
          stats::lm(df[[pos_2]] ~ as.factor(df[[pos_1]])))[["r.squared"]])
    }
    
    # both are factor/character
    if(class(df[[pos_1]]) %in% c("factor", "character") &&
       class(df[[pos_2]]) %in% c("factor", "character")){
      r <- lsr::cramersV(df[[pos_1]], df[[pos_2]], simulate.p.value = TRUE)
    }
    
    return(r)
  } 
  
  cor_fun <- Vectorize(cor_fun)
  
  # now compute corr matrix
  corrmat <- outer(1:ncol(df)
                   , 1:ncol(df)
                   , function(x, y) cor_fun(x, y)
  )
  
  rownames(corrmat) <- colnames(df)
  colnames(corrmat) <- colnames(df)
  
  return(corrmat)
}
##########################################p1
death = read.csv("../../data_week7/data/murder_suicide.csv")
death %>% 
  mutate(age = ifelse(AgeType == 1, Age, 0), 
         education = ifelse(EducationReportingFlag == 1, Education2003Revision*2, Education1989Revision)) -> death
death %>% 
  select(Id, ResidentStatus, education, Sex,  age,MonthOfDeath, PlaceOfDeathAndDecedentsStatus,
         MaritalStatus, DayOfWeekOfDeath, InjuryAtWork, ActivityCode,PlaceOfInjury,
         Race,MannerOfDeath, MethodOfDisposition) -> death_data
death_data %>% 
  filter(MannerOfDeath == 2 | MannerOfDeath == 3) %>%
  filter(age <= 100) %>% filter(education <= 20) -> death_data
death_data %>%
  mutate(suicide = ifelse(MannerOfDeath == 3, 0, 1)) -> death_data
death_data$MannerOfDeath <- NULL

cor2(death_data) -> cor_matrix
melted_cor_matrix <- melt(cor_matrix)
ggplot(data = melted_cor_matrix, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() + theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.6))

scatterplotMatrix(sample_n(death_data, 1500))

```
<p dir = "RTL">
تابع cor2 برای این است که بتوان همبستگی متغیرهای کتگوریکال را نیز محاسبه کرد.
</p>
***

<p dir="RTL">
۲. اثر هر یک از متغیرهای جنسیت، نژاد،آموزش، سن و نحوه تدفین را بر مرگ یا خودکشی ارزیابی کنید.
</p>

<p dir = "RTL">
پاسخ :
</p>

```{r,warning=FALSE}
#asar e jensiat bar manner of death
chisq.test(death_data$suicide, death_data$Sex)
#-> az ham mostaghel nistand

#asar e nejad bar nahve marg
chisq.test(death_data$suicide, death_data$Race)
#-> az ham mostaghel nistand

#asar e amuzesh bar nahve marg
chisq.test(death_data$education, death_data$suicide)
#-> az ham mostaghel nistand

#asar e sen bar nahve marg
chisq.test(death_data$age, death_data$suicide)
#-> az ham mostaghel nistand

#nahve tadfin
chisq.test(death_data$MethodOfDisposition, death_data$suicide)
#-> az ham mostaghel nistand

```

***

<p dir="RTL">
۳. با استفاده از مدل رگرسیون لاجستیک یک مدل به داده ها برازش دهید و سپس آن را نقص یابی کنید.
</p>

<p dir = "RTL">
پاسخ :
</p>

```{r}
fit = glm(suicide ~ 
          ResidentStatus + education + Sex  + age + 
          MonthOfDeath + PlaceOfDeathAndDecedentsStatus +
          MaritalStatus + DayOfWeekOfDeath + InjuryAtWork +
          ActivityCode + PlaceOfInjury +
          Race + MethodOfDisposition, data = death_data)
summary(fit)
#banabar in race va month of death ra estefade nmikonim
fit = glm(suicide ~ 
            ResidentStatus + education + Sex  + age + 
            PlaceOfDeathAndDecedentsStatus +
            MaritalStatus + DayOfWeekOfDeath + InjuryAtWork +
            ActivityCode + PlaceOfInjury +
            MethodOfDisposition, data = death_data)

library(boot)
glm.diag.plots(fit, glmdiag = glm.diag(fit))


```

***

<p dir="RTL">
۴. با استفاده از سه نمودار خروجی مدل را نسبت به داده واقعی ارزیابی کنید.
</p>

<p dir="RTL">
پاسخ :
</p>
```{r}
death_data = death_data %>% mutate(pred = fitted(fit)) 
ggplot(death_data,aes(x = age,y = pred,col = suicide))+
  geom_point()

ggplot(death_data,aes(x = education,y = pred,col = suicide))+
  geom_point()

ggplot(data = death_data, aes(x = PlaceOfInjury, y = suicide)) + geom_point() + 
  geom_line(aes(x = PlaceOfInjury, y = pred), color = 'red', size = 0.3)

ggplot( death_data, aes( pred, color = as.factor(suicide))) + 
  geom_density( size = 1 )
```

***

<p dir="RTL">
۵. ابتدا ۲۰ درصد داده را به صورت تصادفی به عنوان تست در نظر بگیرید. مدل را با استفاده از ۸۰ درصد باقی مانده برازش دهید. با استفاده از پارامتر قطع ۰.۵ نتایج را برای داده تست پیش بینی کنید. سپس کمیت های زیر را محاسبه کنید.
</p>

* P: positive samples
* N: negative samples
* TP: true positive TP (eqv. with hit)
* TN: true negative (eqv. with correct rejection)
* FP: false positive (eqv. with false alarm, Type I error)
* FN: false negative (eqv. with miss, Type II error)
* Accuracy (ACC) ACC = (TP+TN)/(P+T)
* False positive rate (FPR): 1- TN/N
* True positive rate (TPR): TP/P

<p dir="RTL">
مشابه آنچه در کلاس گفته شد نمایشی از  چهار کمیت 
TN, TP,FP,FN
به همراه داده ها رسم نمایید.
</p>

<p dir = "RTL">
پاسخ :
</p>
```{r, warning=FALSE, message=FALSE}
index = sample(x= 1:nrow(death_data),size = 0.8*nrow(death_data),replace = F)
train = death_data[index,] 
test =  death_data[-index,]

model = glm(suicide ~ 
      ResidentStatus + education + Sex  + age + 
      PlaceOfDeathAndDecedentsStatus +
      MaritalStatus + DayOfWeekOfDeath + InjuryAtWork +
      ActivityCode + PlaceOfInjury +
      MethodOfDisposition, data = train)
# prediction
train$prediction = predict( model, newdata = train, type = "response" )
test$prediction  = predict( model, newdata = test , type = "response" )

cm_info = ConfusionMatrixInfo( data = test, predict = "prediction", 
                               actual = "suicide", cutoff = .5 )
cm_info$plot


TP =  sum((test$prediction > 0.5) & (test$suicide == 1))
TN = sum((test$prediction < 0.5) & (test$suicide == 0))
FP = sum((test$prediction > 0.5) & (test$suicide == 0))
FN = sum((test$prediction < 0.5) & (test$suicide == 1))
P = TP + FP
N =  TN + FN
ACC = (TP+TN)/(P+N)
FPR = 1- TN/N
TPR = TP/P

TP
TN
FP
FN
P
N
ACC
FPR
TPR
```

***

<p dir="RTL">
۶. نمودار صحت مدل (accuracy) را بر حسب مقادیر مختلف قطع برای داده تست رسم نمایید. کدام پارامتر قطع بالاترین صحت را در پیش بینی داراست؟
</p>

<p dir="RTL">
پاسخ :
</p>

```{r, warning=FALSE}
test_acc = c();
train_acc = c();
cutoff = seq(0.4, 0.8, 0.05)

for (i in seq(0.4, 0.8, 0.05)) {
  TP =  sum((test$prediction > i) & (test$suicide == 1))
  TN = sum((test$prediction < i) & (test$suicide == 0))
  FP = sum((test$prediction > i) & (test$suicide == 0))
  FN = sum((test$prediction < i) & (test$suicide == 1))
  P = TP + FP
  N =  TN + FN
  ACC = (TP+TN)/(P+N)
  test_acc = c(test_acc, ACC)  
  TP =  sum((train$prediction > i) & (train$suicide == 1))
  TN = sum((train$prediction < i) & (train$suicide == 0))
  FP = sum((train$prediction > i) & (train$suicide == 0))
  FN = sum((train$prediction < i) & (train$suicide == 1))
  P = TP + FP
  N =  TN + FN
  ACC = (TP+TN)/(P+N)
  train_acc = c(train_acc, ACC)  
}

data.frame(cutoff = cutoff,
           Accuracy = c(test_acc, train_acc),
           type = rep(c('Test', "Train"), each = length(test_acc)) ) %>% 
  ggplot(aes(x = cutoff, y = Accuracy, col = type))+
  geom_line()+ 
  geom_point()

```

***

<p dir="RTL">
۷. نمودار 
ROC
 را برای داده های قسمت قبل رسم نمایید. همچنین نقطه مربوط به بهترین پارامتر قطع را مشخص نمایید.
</p>

<p dir = "RTL">
پاسخ :
</p>

```{r, warning=FALSE}
cm_info = ConfusionMatrixInfo( data = test, predict = "prediction", 
                               actual = "suicide", cutoff = .5 )
cost_fp = 100;cost_fn = 200
roc_info = ROCInfo( data = cm_info$data, predict = "predict", 
                    actual = "actual", cost.fp = cost_fp, cost.fn = cost_fn )
grid.draw(roc_info$plot)

```

***

<p dir="RTL">
۸. با قرار دادن کمیت 
nfolds = 5
و با استفاده از 
H20
مدل مساله را بسازید و نتیجه حاصل را ارزیابی کنید.
</p>

<p dir = "RTL">
پاسخ :
</p>
```{r, warning=FALSE, message=FALSE}
library(h2o)
h2o.init()
hdeath = as.h2o(death_data)
chglm = h2o.glm(y = "suicide", x= c("ResidentStatus", "education", "Sex", "age", 
                                      "PlaceOfDeathAndDecedentsStatus",
                                      "MaritalStatus", "DayOfWeekOfDeath", "InjuryAtWork",
                                      "ActivityCode", "PlaceOfInjury",
                                      "MethodOfDisposition"),
                training_frame = hdeath,nfolds = 5)
chglm
h2o.confusionMatrix(chglm)
```


***

<p dir="RTL"> 
۹. آیا ما میتوانیم سرویسی به قضات ارایه کنیم تا با استفاده از اطلاعات مرگ بتوانند موارد مشکوک به قتل را از خودکشی تفکیک دهند؟
</p>

<p dir="RTL">
پاسخ :
</p>

<p dir = "RTL">
با این داده و خطا خیر زیرا برای این کار باید خطا بسیار پایین باشد اما ممکن است اگر داده بیشتری داشته باشیم و مدل بهتری که خطای کمتری داشته باشد بتوان این کار را انجام داد. همچنین ممکن است اگر پارامتر های دیگری داشته باشیم با آن پارامترها بتوان مدل بهتری پیدا کرد.
</p>

